{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3214f233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports & configuration\n",
    "import os, random, time, math\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "device = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# Paths\n",
    "HR_DIR = Path(\"train_HR\")\n",
    "LR_DIR = Path(\"train_LR\")\n",
    "assert HR_DIR.exists() and LR_DIR.exists(), \"HR/LR directories must exist.\"\n",
    "\n",
    "SCALE = 4\n",
    "HR_EXPECTED = (1024, 1024)   # UPDATED\n",
    "PATCH_HR = 128               # still fine; you can raise to 192 or 256 later\n",
    "PATCH_LR = PATCH_HR // SCALE\n",
    "BATCH_SIZE = 16\n",
    "VAL_RATIO = 0.1\n",
    "EPOCHS = 120\n",
    "VIRTUAL_PATCHES_PER_EPOCH = 3000\n",
    "LEARNING_RATE = 1e-3\n",
    "EDGE_LOSS_WEIGHT = 0.0         # start at 0; add later if needed\n",
    "EARLY_STOP_PATIENCE = 15\n",
    "CHECKPOINT_DIR = Path(\"checkpoints_espcn\")\n",
    "CHECKPOINT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "LOG_FILE = CHECKPOINT_DIR / \"train_log.csv\"\n",
    "KEEP_LAST = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e1cf254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total common files: 111 | Usable pairs: 111 | Problems: 0\n",
      "Train pairs: 100 | Val pairs: 11\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Robust paired list + split\n",
    "VALID_EXT = {\".png\",\".jpg\",\".jpeg\",\".bmp\",\".webp\"}\n",
    "\n",
    "def list_images(folder):\n",
    "    return [p for p in folder.iterdir() if p.suffix.lower() in VALID_EXT]\n",
    "\n",
    "hr_files = list_images(HR_DIR)\n",
    "lr_files = list_images(LR_DIR)\n",
    "hr_map = {p.stem: p for p in hr_files}\n",
    "lr_map = {p.stem: p for p in lr_files}\n",
    "\n",
    "common_keys = sorted(set(hr_map.keys()) & set(lr_map.keys()))\n",
    "missing_hr = sorted(set(lr_map.keys()) - set(hr_map.keys()))\n",
    "missing_lr = sorted(set(hr_map.keys()) - set(lr_map.keys()))\n",
    "\n",
    "if missing_hr:\n",
    "    print(\"Warning: LR without HR:\", missing_hr[:5], \"…\")\n",
    "if missing_lr:\n",
    "    print(\"Warning: HR without LR:\", missing_lr[:5], \"…\")\n",
    "\n",
    "pairs = []\n",
    "problems = []\n",
    "for k in common_keys:\n",
    "    hr_p = hr_map[k]\n",
    "    lr_p = lr_map[k]\n",
    "    with Image.open(hr_p) as H, Image.open(lr_p) as L:\n",
    "        if HR_EXPECTED and H.size != HR_EXPECTED:\n",
    "            problems.append((hr_p.name, f\"HR size {H.size}\"))\n",
    "            continue\n",
    "        if (H.size[0] != L.size[0]*SCALE) or (H.size[1] != L.size[1]*SCALE):\n",
    "            problems.append((k, f\"scale mismatch HR={H.size} LR={L.size}\"))\n",
    "            continue\n",
    "    pairs.append((hr_p, lr_p))\n",
    "\n",
    "print(f\"Total common files: {len(common_keys)} | Usable pairs: {len(pairs)} | Problems: {len(problems)}\")\n",
    "if problems[:5]:\n",
    "    print(\"Sample problems:\", problems[:5])\n",
    "\n",
    "# Shuffle & split\n",
    "random.shuffle(pairs)\n",
    "val_count = max(8, int(len(pairs)*VAL_RATIO))\n",
    "val_pairs = pairs[:val_count]\n",
    "train_pairs = pairs[val_count:]\n",
    "print(f\"Train pairs: {len(train_pairs)} | Val pairs: {len(val_pairs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2218c452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR shape: torch.Size([16, 3, 32, 32]) HR shape: torch.Size([16, 3, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Dataset with random aligned patch crops + simple aug (flips)\n",
    "class SRDataset(Dataset):\n",
    "    def __init__(self, pairs, scale=4, hr_patch=128, augment=True, y_only=False):\n",
    "        self.pairs = pairs\n",
    "        self.scale = scale\n",
    "        self.hr_patch = hr_patch\n",
    "        self.lr_patch = hr_patch // scale\n",
    "        self.augment = augment\n",
    "        self.y_only = y_only\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def _load(self, idx):\n",
    "        hr_p, lr_p = self.pairs[idx]\n",
    "        hr = Image.open(hr_p).convert(\"RGB\")\n",
    "        lr = Image.open(lr_p).convert(\"RGB\")\n",
    "        return hr, lr, hr_p.name\n",
    "\n",
    "    def _crop(self, hr, lr):\n",
    "        w_hr, h_hr = hr.size\n",
    "        w_lr, h_lr = lr.size\n",
    "        if self.hr_patch >= w_hr:  # full image fallback\n",
    "            return hr, lr\n",
    "        # choose LR coordinate\n",
    "        x_lr = random.randint(0, w_lr - self.lr_patch)\n",
    "        y_lr = random.randint(0, h_lr - self.lr_patch)\n",
    "        x_hr, y_hr = x_lr * self.scale, y_lr * self.scale\n",
    "        hr_c = hr.crop((x_hr, y_hr, x_hr + self.hr_patch, y_hr + self.hr_patch))\n",
    "        lr_c = lr.crop((x_lr, y_lr, x_lr + self.lr_patch, y_lr + self.lr_patch))\n",
    "        return hr_c, lr_c\n",
    "\n",
    "    def _augment(self, hr, lr):\n",
    "        if random.random() < 0.5:\n",
    "            hr = hr.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            lr = lr.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "        if random.random() < 0.5:\n",
    "            hr = hr.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "            lr = lr.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "        return hr, lr\n",
    "\n",
    "    def _to_tensor(self, img):\n",
    "        arr = np.array(img).astype(\"float32\")/255.0\n",
    "        if self.y_only:\n",
    "            r,g,b = arr[...,0], arr[...,1], arr[...,2]\n",
    "            y = 0.299*r + 0.587*g + 0.114*b\n",
    "            arr = y[...,None]\n",
    "        arr = arr.transpose(2,0,1)\n",
    "        return torch.from_numpy(arr)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        hr, lr, name = self._load(idx)\n",
    "        hr, lr = self._crop(hr, lr)\n",
    "        if self.augment:\n",
    "            hr, lr = self._augment(hr, lr)\n",
    "        hr_t = self._to_tensor(hr)\n",
    "        lr_t = self._to_tensor(lr)\n",
    "        return {\"lr\": lr_t, \"hr\": hr_t, \"name\": name}\n",
    "\n",
    "train_ds = SRDataset(train_pairs, scale=SCALE, hr_patch=PATCH_HR, augment=True)\n",
    "val_ds   = SRDataset(val_pairs,   scale=SCALE, hr_patch=HR_EXPECTED[0], augment=False)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=0, drop_last=True)\n",
    "val_loader   = DataLoader(val_ds, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "print(\"LR shape:\", batch[\"lr\"].shape, \"HR shape:\", batch[\"hr\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c5838fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params (M): 0.106417\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Model (ESPCN variant). Use your espcn_x4 if you trust it; else this.\n",
    "class ESPCN(nn.Module):\n",
    "    def __init__(self, in_ch=3, out_ch=3, scale=4, feat=64, hidden=2, activation='prelu', residual_skip=True):\n",
    "        super().__init__()\n",
    "        act = {'relu': nn.ReLU(True), 'prelu': nn.PReLU(), 'gelu': nn.GELU()}.get(activation.lower(), nn.PReLU())\n",
    "        layers = [nn.Conv2d(in_ch, feat, 5, padding=2), act]\n",
    "        for _ in range(hidden):\n",
    "            layers += [nn.Conv2d(feat, feat, 3, padding=1), act]\n",
    "        layers += [nn.Conv2d(feat, out_ch * (scale**2), 3, padding=1)]\n",
    "        self.body = nn.Sequential(*layers)\n",
    "        self.ps = nn.PixelShuffle(scale)\n",
    "        self.residual_skip = residual_skip\n",
    "        self.scale = scale\n",
    "        self.out_ch = out_ch\n",
    "        self.apply(self._init)\n",
    "\n",
    "    def _init(self, m):\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "            if m.bias is not None:\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.ps(self.body(x))\n",
    "        if self.residual_skip:\n",
    "            up = F.interpolate(x, scale_factor=self.scale, mode='bicubic', align_corners=False)\n",
    "            if up.shape[1] != self.out_ch:\n",
    "                up = up[:, :self.out_ch]\n",
    "            y = y + up\n",
    "        return y\n",
    "\n",
    "# If you prefer your external espcn_x4 factory, swap:\n",
    "# from espcn import espcn_x4\n",
    "# model = espcn_x4(in_channels=3, out_channels=3, channels=64).to(device)\n",
    "model = ESPCN(scale=SCALE, feat=64, hidden=2, activation='prelu', residual_skip=True).to(device)\n",
    "print(\"Params (M):\", sum(p.numel() for p in model.parameters())/1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b6b8e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Loss (Charbonnier instead of pure MSE) + optional edge loss\n",
    "class CharbonnierLoss(nn.Module):\n",
    "    def __init__(self, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "    def forward(self, pred, target):\n",
    "        return torch.mean(torch.sqrt((pred - target)**2 + self.eps))\n",
    "\n",
    "def to_y(x):\n",
    "    if x.shape[1] == 1: return x\n",
    "    r,g,b = x[:,0:1], x[:,1:2], x[:,2:3]\n",
    "    return 0.299*r + 0.587*g + 0.114*b\n",
    "\n",
    "def psnr(sr, hr):\n",
    "    mse = torch.mean((sr - hr)**2)\n",
    "    if mse.item() == 0:\n",
    "        return 99.0\n",
    "    return 20 * torch.log10(1.0 / torch.sqrt(mse))\n",
    "\n",
    "def psnr_y(sr, hr):\n",
    "    return psnr(to_y(sr), to_y(hr))\n",
    "\n",
    "# Edge loss (disabled initially)\n",
    "def sobel_edges(x):\n",
    "    if x.shape[1] > 1:\n",
    "        x = to_y(x)\n",
    "    gx = torch.tensor([[1,0,-1],[2,0,-2],[1,0,-1]], device=x.device, dtype=x.dtype).view(1,1,3,3)\n",
    "    gy = torch.tensor([[1,2,1],[0,0,0],[-1,-2,-1]], device=x.device, dtype=x.dtype).view(1,1,3,3)\n",
    "    x_pad = F.pad(x, (1,1,1,1), mode='reflect')\n",
    "    sx = F.conv2d(x_pad, gx)\n",
    "    sy = F.conv2d(x_pad, gy)\n",
    "    return torch.sqrt(sx*sx + sy*sy + 1e-8)\n",
    "\n",
    "BASE_LOSS = CharbonnierLoss()\n",
    "def compute_loss(sr, hr):\n",
    "    base = BASE_LOSS(sr, hr)\n",
    "    if EDGE_LOSS_WEIGHT > 0:\n",
    "        base += EDGE_LOSS_WEIGHT * BASE_LOSS(sobel_edges(sr), sobel_edges(hr))\n",
    "    return base\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e1956e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | train_loss 0.0316 | val_PSNR(Y) 30.55 dB | lr 1.000e-03 IMPROVED\n",
      "Epoch 002 | train_loss 0.0276 | val_PSNR(Y) 30.76 dB | lr 1.000e-03 IMPROVED\n",
      "Epoch 002 | train_loss 0.0276 | val_PSNR(Y) 30.76 dB | lr 1.000e-03 IMPROVED\n",
      "Epoch 003 | train_loss 0.0262 | val_PSNR(Y) 30.47 dB | lr 1.000e-03 \n",
      "Epoch 003 | train_loss 0.0262 | val_PSNR(Y) 30.47 dB | lr 1.000e-03 \n",
      "Epoch 004 | train_loss 0.0258 | val_PSNR(Y) 30.33 dB | lr 1.000e-03 \n",
      "Epoch 004 | train_loss 0.0258 | val_PSNR(Y) 30.33 dB | lr 1.000e-03 \n",
      "Epoch 005 | train_loss 0.0253 | val_PSNR(Y) 30.80 dB | lr 1.000e-03 IMPROVED\n",
      "Epoch 005 | train_loss 0.0253 | val_PSNR(Y) 30.80 dB | lr 1.000e-03 IMPROVED\n",
      "Epoch 006 | train_loss 0.0251 | val_PSNR(Y) 30.75 dB | lr 1.000e-03 \n",
      "Epoch 006 | train_loss 0.0251 | val_PSNR(Y) 30.75 dB | lr 1.000e-03 \n",
      "Epoch 007 | train_loss 0.0247 | val_PSNR(Y) 30.58 dB | lr 1.000e-03 \n",
      "Epoch 007 | train_loss 0.0247 | val_PSNR(Y) 30.58 dB | lr 1.000e-03 \n",
      "Epoch 008 | train_loss 0.0245 | val_PSNR(Y) 30.82 dB | lr 1.000e-03 IMPROVED\n",
      "Epoch 008 | train_loss 0.0245 | val_PSNR(Y) 30.82 dB | lr 1.000e-03 IMPROVED\n",
      "Epoch 009 | train_loss 0.0246 | val_PSNR(Y) 30.81 dB | lr 1.000e-03 \n",
      "Epoch 009 | train_loss 0.0246 | val_PSNR(Y) 30.81 dB | lr 1.000e-03 \n",
      "Epoch 010 | train_loss 0.0245 | val_PSNR(Y) 30.83 dB | lr 1.000e-03 IMPROVED\n",
      "Epoch 010 | train_loss 0.0245 | val_PSNR(Y) 30.83 dB | lr 1.000e-03 IMPROVED\n",
      "Epoch 011 | train_loss 0.0244 | val_PSNR(Y) 30.70 dB | lr 1.000e-03 \n",
      "Epoch 011 | train_loss 0.0244 | val_PSNR(Y) 30.70 dB | lr 1.000e-03 \n",
      "Epoch 012 | train_loss 0.0243 | val_PSNR(Y) 30.86 dB | lr 1.000e-03 IMPROVED\n",
      "Epoch 012 | train_loss 0.0243 | val_PSNR(Y) 30.86 dB | lr 1.000e-03 IMPROVED\n",
      "Epoch 013 | train_loss 0.0245 | val_PSNR(Y) 30.95 dB | lr 1.000e-03 IMPROVED\n",
      "Epoch 013 | train_loss 0.0245 | val_PSNR(Y) 30.95 dB | lr 1.000e-03 IMPROVED\n",
      "Epoch 014 | train_loss 0.0243 | val_PSNR(Y) 30.98 dB | lr 1.000e-03 IMPROVED\n",
      "Epoch 014 | train_loss 0.0243 | val_PSNR(Y) 30.98 dB | lr 1.000e-03 IMPROVED\n",
      "Epoch 015 | train_loss 0.0242 | val_PSNR(Y) 30.94 dB | lr 1.000e-03 \n",
      "Epoch 015 | train_loss 0.0242 | val_PSNR(Y) 30.94 dB | lr 1.000e-03 \n",
      "Epoch 016 | train_loss 0.0242 | val_PSNR(Y) 30.83 dB | lr 1.000e-03 \n",
      "Epoch 016 | train_loss 0.0242 | val_PSNR(Y) 30.83 dB | lr 1.000e-03 \n",
      "Epoch 017 | train_loss 0.0242 | val_PSNR(Y) 30.71 dB | lr 1.000e-03 \n",
      "Epoch 017 | train_loss 0.0242 | val_PSNR(Y) 30.71 dB | lr 1.000e-03 \n",
      "Epoch 018 | train_loss 0.0242 | val_PSNR(Y) 30.82 dB | lr 1.000e-03 \n",
      "Epoch 018 | train_loss 0.0242 | val_PSNR(Y) 30.82 dB | lr 1.000e-03 \n",
      "Epoch 019 | train_loss 0.0243 | val_PSNR(Y) 30.72 dB | lr 1.000e-03 \n",
      "Epoch 019 | train_loss 0.0243 | val_PSNR(Y) 30.72 dB | lr 1.000e-03 \n",
      "Epoch 020 | train_loss 0.0241 | val_PSNR(Y) 30.75 dB | lr 5.000e-04 \n",
      "Epoch 020 | train_loss 0.0241 | val_PSNR(Y) 30.75 dB | lr 5.000e-04 \n",
      "Epoch 021 | train_loss 0.0239 | val_PSNR(Y) 30.83 dB | lr 5.000e-04 \n",
      "Epoch 021 | train_loss 0.0239 | val_PSNR(Y) 30.83 dB | lr 5.000e-04 \n",
      "Epoch 022 | train_loss 0.0238 | val_PSNR(Y) 30.87 dB | lr 5.000e-04 \n",
      "Epoch 022 | train_loss 0.0238 | val_PSNR(Y) 30.87 dB | lr 5.000e-04 \n",
      "Epoch 023 | train_loss 0.0239 | val_PSNR(Y) 30.83 dB | lr 5.000e-04 \n",
      "Epoch 023 | train_loss 0.0239 | val_PSNR(Y) 30.83 dB | lr 5.000e-04 \n",
      "Epoch 024 | train_loss 0.0238 | val_PSNR(Y) 30.86 dB | lr 5.000e-04 \n",
      "Epoch 024 | train_loss 0.0238 | val_PSNR(Y) 30.86 dB | lr 5.000e-04 \n",
      "Epoch 025 | train_loss 0.0235 | val_PSNR(Y) 30.87 dB | lr 5.000e-04 \n",
      "Epoch 025 | train_loss 0.0235 | val_PSNR(Y) 30.87 dB | lr 5.000e-04 \n",
      "Epoch 026 | train_loss 0.0239 | val_PSNR(Y) 30.79 dB | lr 2.500e-04 \n",
      "Epoch 026 | train_loss 0.0239 | val_PSNR(Y) 30.79 dB | lr 2.500e-04 \n",
      "Epoch 027 | train_loss 0.0236 | val_PSNR(Y) 30.84 dB | lr 2.500e-04 \n",
      "Epoch 027 | train_loss 0.0236 | val_PSNR(Y) 30.84 dB | lr 2.500e-04 \n",
      "Epoch 028 | train_loss 0.0237 | val_PSNR(Y) 30.68 dB | lr 2.500e-04 \n",
      "Epoch 028 | train_loss 0.0237 | val_PSNR(Y) 30.68 dB | lr 2.500e-04 \n",
      "Epoch 029 | train_loss 0.0239 | val_PSNR(Y) 30.80 dB | lr 2.500e-04 \n",
      "Early stopping at epoch 29. Best PSNR(Y)=30.98\n",
      "Training complete. Best PSNR(Y): 30.984372919256035\n",
      "Epoch 029 | train_loss 0.0239 | val_PSNR(Y) 30.80 dB | lr 2.500e-04 \n",
      "Early stopping at epoch 29. Best PSNR(Y)=30.98\n",
      "Training complete. Best PSNR(Y): 30.984372919256035\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Training + validation + logging\n",
    "if not LOG_FILE.exists():\n",
    "    with open(LOG_FILE, 'w') as f:\n",
    "        f.write(\"epoch,train_loss,val_psnr_y,lr,time\\n\")\n",
    "\n",
    "BEST_PSNR = -1.0\n",
    "epochs_no_improve = 0\n",
    "\n",
    "def validate():\n",
    "    model.eval()\n",
    "    scores = []\n",
    "    with torch.no_grad():\n",
    "        for b in val_loader:\n",
    "            lr_t = b[\"lr\"].to(device)\n",
    "            hr_t = b[\"hr\"].to(device)\n",
    "            sr = model(lr_t).clamp(0,1)\n",
    "            scores.append(psnr_y(sr, hr_t).item())\n",
    "    return sum(scores)/len(scores)\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    running = 0.0\n",
    "    steps = 0\n",
    "    # Virtual epoch: sample random patches\n",
    "    while steps < VIRTUAL_PATCHES_PER_EPOCH:\n",
    "        for b in train_loader:\n",
    "            lr_t = b[\"lr\"].to(device)\n",
    "            hr_t = b[\"hr\"].to(device)\n",
    "            sr = model(lr_t)\n",
    "            loss = compute_loss(sr, hr_t)\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running += loss.item()\n",
    "            steps += 1\n",
    "            if steps >= VIRTUAL_PATCHES_PER_EPOCH:\n",
    "                break\n",
    "    train_loss = running / steps\n",
    "    val_psnr = validate()\n",
    "    scheduler.step(val_psnr)\n",
    "\n",
    "    lr_now = optimizer.param_groups[0]['lr']\n",
    "    improved = val_psnr > BEST_PSNR\n",
    "    tag = \"IMPROVED\" if improved else \"\"\n",
    "    print(f\"Epoch {epoch:03d} | train_loss {train_loss:.4f} | val_PSNR(Y) {val_psnr:.2f} dB | lr {lr_now:.3e} {tag}\")\n",
    "\n",
    "    with open(LOG_FILE, 'a') as f:\n",
    "        f.write(f\"{epoch},{train_loss:.6f},{val_psnr:.4f},{lr_now:.6e},{int(time.time())}\\n\")\n",
    "\n",
    "    if improved:\n",
    "        BEST_PSNR = val_psnr\n",
    "        epochs_no_improve = 0\n",
    "        ckpt_path = CHECKPOINT_DIR / f\"epoch{epoch:03d}_psnr{val_psnr:.2f}.pt\"\n",
    "        torch.save({\n",
    "            \"epoch\": epoch,\n",
    "            \"model\": model.state_dict(),\n",
    "            \"optimizer\": optimizer.state_dict(),\n",
    "            \"val_psnr_y\": val_psnr\n",
    "        }, ckpt_path)\n",
    "        # prune\n",
    "        ckpts = sorted(CHECKPOINT_DIR.glob(\"epoch*.pt\"))\n",
    "        if len(ckpts) > KEEP_LAST:\n",
    "            for old in ckpts[:-KEEP_LAST]:\n",
    "                old.unlink()\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= EARLY_STOP_PATIENCE:\n",
    "            print(f\"Early stopping at epoch {epoch}. Best PSNR(Y)={BEST_PSNR:.2f}\")\n",
    "            break\n",
    "\n",
    "print(\"Training complete. Best PSNR(Y):\", BEST_PSNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e576bf0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded best: epoch014_psnr30.98.pt val_PSNR(Y)= 30.984372919256035\n",
      "Saved: checkpoints_espcn/espcn_best_state.pth\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "ckpt_dir = CHECKPOINT_DIR  # same dir you used\n",
    "ckpts = list(ckpt_dir.glob(\"epoch*_psnr*.pt\"))\n",
    "assert ckpts, \"No checkpoints found.\"\n",
    "\n",
    "def extract_psnr(p):\n",
    "    m = re.search(r\"psnr([0-9]+(?:\\.[0-9]+)?)\", p.stem)\n",
    "    return float(m.group(1)) if m else -1.0\n",
    "\n",
    "best_ckpt = max(ckpts, key=extract_psnr)\n",
    "state = torch.load(best_ckpt, map_location='cpu')\n",
    "model.load_state_dict(state['model'])\n",
    "print(\"Loaded best:\", best_ckpt.name, \"val_PSNR(Y)=\", state.get(\"val_psnr_y\"))\n",
    "\n",
    "# Save consolidated state dict\n",
    "final_path = ckpt_dir / \"espcn_best_state.pth\"\n",
    "torch.save(model.state_dict(), final_path)\n",
    "print(\"Saved:\", final_path)\n",
    "\n",
    "# (Optional) full package (state + config)\n",
    "torch.save({\n",
    "    \"model_state\": model.state_dict(),\n",
    "    \"scale\": SCALE,\n",
    "    \"patch_hr\": PATCH_HR,\n",
    "    \"best_val_psnr_y\": state.get(\"val_psnr_y\"),\n",
    "}, ckpt_dir / \"espcn_package.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26aa9f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(weights_path):\n",
    "    m = ESPCN(scale=SCALE, feat=64, hidden=2, activation='prelu', residual_skip=True)\n",
    "    m.load_state_dict(torch.load(weights_path, map_location='cpu'))\n",
    "    m.to(device).eval()\n",
    "    return m\n",
    "\n",
    "# If you just saved espcn_best_state.pth\n",
    "inference_model = load_model(final_path)\n",
    "\n",
    "def upscale_file(lr_path, out_path):\n",
    "    img = Image.open(lr_path).convert('RGB')\n",
    "    arr = np.array(img).astype('float32') / 255.0\n",
    "    t = torch.from_numpy(arr).permute(2,0,1).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        sr = inference_model(t).clamp(0,1)\n",
    "    sr_img = (sr[0].permute(1,2,0).cpu().numpy()*255).round().astype('uint8')\n",
    "    Image.fromarray(sr_img).save(out_path)\n",
    "    return out_path\n",
    "\n",
    "# Example\n",
    "# upscale_file(\"test_LR/sample.png\", \"sr_sample.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36f081a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train_SR/sak-yant-buffalo-tattoo-design.jpeg'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upscale_file(\"train_LR/sak-yant-buffalo-tattoo-design.jpeg\", \"train_SR/sak-yant-buffalo-tattoo-design.jpeg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Project-ksHmrzpc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
