{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2ce69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from espcn import espcn_x4\n",
    "\n",
    "class PairedDataset(Dataset):\n",
    "    def __init__(self, lr_dir, hr_dir):\n",
    "        self.lr_files = sorted([os.path.join(lr_dir, f) for f in os.listdir(lr_dir)])\n",
    "        self.hr_files = sorted([os.path.join(hr_dir, f) for f in os.listdir(hr_dir)])\n",
    "\n",
    "        # Both images to tensor, normalized [0,1]\n",
    "        self.to_tensor = transforms.ToTensor()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lr_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        lr = Image.open(self.lr_files[idx]).convert(\"RGB\")\n",
    "        hr = Image.open(self.hr_files[idx]).convert(\"RGB\")\n",
    "\n",
    "        lr = self.to_tensor(lr)  # (3, H, W)\n",
    "        hr = self.to_tensor(hr)  # (3, H, W)\n",
    "\n",
    "        return lr, hr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b0e999a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, lr_dir, hr_dir, transform=None):\n",
    "        self.lr_dir = lr_dir\n",
    "        self.hr_dir = hr_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # Only keep valid image files\n",
    "        valid_exts = (\".png\", \".jpg\", \".jpeg\", \".bmp\")\n",
    "        self.lr_images = [f for f in os.listdir(lr_dir) if f.lower().endswith(valid_exts)]\n",
    "        self.hr_images = [f for f in os.listdir(hr_dir) if f.lower().endswith(valid_exts)]\n",
    "\n",
    "        # Sort to ensure matching order\n",
    "        self.lr_images.sort()\n",
    "        self.hr_images.sort()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lr_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        lr_path = os.path.join(self.lr_dir, self.lr_images[idx])\n",
    "        hr_path = os.path.join(self.hr_dir, self.hr_images[idx])\n",
    "\n",
    "        lr = Image.open(lr_path).convert(\"RGB\")\n",
    "        hr = Image.open(hr_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            lr = self.transform(lr)\n",
    "            hr = self.transform(hr)\n",
    "\n",
    "        return lr, hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c1942d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "lr_dir = \"train_LR\"\n",
    "hr_dir = \"train_HR\"\n",
    "\n",
    "transform = transforms.ToTensor()  # Converts to tensor in [0,1]\n",
    "\n",
    "dataset = ImageDataset(lr_dir, hr_dir, transform=transform)\n",
    "train_loader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=0)\n",
    "\n",
    "\n",
    "# Model   # use your file, e.g., espcn.py\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = espcn_x4(in_channels=3, out_channels=3, channels=64).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3468031",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for lr, hr in train_loader:\n",
    "        lr, hr = lr.to(device), hr.to(device)\n",
    "\n",
    "        sr = model(lr)              # super-resolved output\n",
    "        loss = criterion(sr, hr)    # pixel-wise MSE loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss/len(train_loader):.6f}\")\n",
    "\n",
    "    # Save checkpoint\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        torch.save(model.state_dict(), f\"epoch_result/espcn_epoch{epoch+1}.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565c9e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "model.eval()\n",
    "total_psnr, total_ssim = 0, 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for lr, hr in val_loader:\n",
    "        lr, hr = lr.to(device), hr.to(device)\n",
    "        sr = model(lr)\n",
    "\n",
    "        sr = torch.clamp(sr, 0, 1)  # Ensure values in range\n",
    "        sr_np = sr.squeeze(0).permute(1,2,0).cpu().numpy()\n",
    "        hr_np = hr.squeeze(0).permute(1,2,0).cpu().numpy()\n",
    "\n",
    "        total_psnr += psnr(hr_np, sr_np, data_range=1.0)\n",
    "        total_ssim += ssim(hr_np, sr_np, channel_axis=2, data_range=1.0)\n",
    "\n",
    "print(\"PSNR:\", total_psnr/len(val_loader))\n",
    "print(\"SSIM:\", total_ssim/len(val_loader))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Project-ksHmrzpc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
